# Active Context: SpendSense

## Current Work Focus
**Status**: PR #24 Complete - Override & Reject Endpoints Complete

## Recent Changes
- ✅ PR #3 Complete: Database Schema & SQLAlchemy Models (all 58 tasks finished)
  - Database configuration complete (SQLite setup with SQLAlchemy)
  - All 10 SQLAlchemy models implemented:
    - User model (user_id, full_name, email, consent fields, user_type)
    - Account model (account_id, user_id, type, balances, currency)
    - Transaction model (transaction_id, account_id, user_id, date, amount, merchant, categories)
    - Liability model (liability_id, account_id, APR fields, payment info)
    - UserFeature model (feature_id, user_id, window_days, behavioral signals)
    - Persona model (persona_id, user_id, persona_type, confidence_score)
    - Recommendation model (recommendation_id, user_id, content, status, approval fields)
    - EvaluationMetric model (metric_id, run_id, performance metrics)
    - ConsentLog model (log_id, user_id, action, timestamp)
    - OperatorAction model (action_id, operator_id, action_type, recommendation_id)
  - Database initialization on FastAPI startup
  - All tables verified with DB Browser for SQLite
  - Database file created: `backend/spendsense.db`
- ✅ PR #4 Complete: Pydantic Schemas for Data Validation (all 31 tasks finished)
  - Created `backend/app/schemas.py` with all validation schemas
  - User schemas: UserBase, UserCreate, UserResponse
  - Account schemas: AccountBase, AccountCreate, AccountResponse
  - Transaction schemas: TransactionBase, TransactionCreate, TransactionResponse (with date parsing)
  - Liability schemas: LiabilityBase, LiabilityCreate, LiabilityResponse (with date parsing)
  - Ingestion schemas: IngestRequest, IngestResponse
  - Feature schemas: UserFeatureResponse
  - Persona schemas: PersonaResponse
  - Recommendation schemas: RecommendationBase, RecommendationCreate, RecommendationResponse, RecommendationApprove, RecommendationOverride, RecommendationReject
  - All schemas use Pydantic v2 syntax with Literal types for enum validation
  - ORM compatibility configured with `from_attributes = True`
  - Validation tested and working
- ✅ PR #5 Complete: Data Ingestion API Endpoint (all 30 tasks finished)
  - FastAPI app updated with CORS middleware (localhost:5173, localhost:3000)
  - Created `backend/app/routers/ingest.py` with POST `/ingest` endpoint
  - Bulk ingestion implemented for all entity types:
    - Users: Bulk insert with transaction commit
    - Accounts: Bulk insert with transaction commit
    - Transactions: Batched processing (1000 per batch) for performance
    - Liabilities: Bulk insert with transaction commit
  - Error handling with rollback on failure
  - Idempotency handling for duplicate key errors (409 status)
  - Returns IngestResponse with counts and duration in milliseconds
  - Test script created (`scripts/test_ingest.py`)
  - All synthetic data successfully ingested:
    - 75 users loaded
    - 272 accounts loaded
    - 15,590 transactions loaded
    - 92 liabilities loaded
  - Data verified in database using SQLite browser
  - Swagger UI accessible at `/docs`
  - Requests dependency added (requests==2.31.0)
- ✅ PR #6 Complete: Feature Detection Service - Subscription Signals (all 22 tasks finished)
  - Created `backend/app/services/feature_detection.py` service file
  - Helper functions implemented:
    - `get_transactions_in_window()` - Queries transactions filtered by date window, ordered by date
    - `get_accounts_by_type()` - Queries accounts filtered by account types
  - Subscription detection implemented:
    - `compute_subscription_signals()` - Main function for subscription pattern detection
    - Groups transactions by merchant_name
    - Filters merchants with ≥3 transactions
    - `is_recurring_pattern()` - Detects recurring patterns:
      - Weekly subscriptions (~7 days ±5 tolerance)
      - Monthly subscriptions (~30 days ±5 tolerance)
      - Quarterly subscriptions (~90 days ±5 tolerance)
    - Calculates signals:
      - `recurring_merchants` (count of merchants with recurring patterns)
      - `monthly_recurring_spend` (sum of recurring transactions / months in window)
      - `subscription_spend_share` (recurring spend / total spend, 0-1 ratio)
  - Test script created (`scripts/test_feature_detection.py`)
  - Tests subscription detection for multiple users with both 30-day and 180-day windows
  - Logs results with merchant examples for validation
- ✅ PR #7 Complete: Feature Detection Service - Savings Signals (all 20 tasks finished)
  - Added `compute_savings_signals()` function to feature_detection.py
  - Savings account filtering:
    - Filters accounts by type: savings, money market, cash management, HSA
    - Returns zero values if no savings accounts found
  - Net inflow calculation:
    - Separates deposits (amount > 0) and withdrawals (amount < 0) per account
    - Calculates net_inflow per account (deposits + withdrawals)
    - Sums net_inflow across all savings accounts
    - Normalizes to monthly net inflow (net_inflow / months_in_window)
  - Growth rate calculation:
    - Calculates start balance (current balance - net inflow)
    - Computes growth rate per account: (current - start) / start
    - Averages growth rates across all savings accounts
  - Emergency fund calculation:
    - Calculates total savings balance across all savings accounts
    - Estimates monthly expenses from checking account transactions (expenses = amount < 0)
    - Calculates emergency_fund_months: savings_balance / avg_monthly_expenses
    - Handles edge case: sets to 0 if expenses = 0
  - Returns dict with:
    - `net_savings_inflow` (float, monthly average)
    - `savings_growth_rate` (float, 0-1, average across accounts)
    - `emergency_fund_months` (float, months of expenses covered)
  - Error handling: Division by zero protection, logging infrastructure
  - Test script updated to test savings detection for users with and without savings accounts
  - Validates growth rate and emergency fund calculations
- ✅ PR #8 Complete: Feature Detection Service - Credit Signals (all 21 tasks finished)
  - Added `compute_credit_signals()` function to feature_detection.py
  - Credit card account querying:
    - Queries credit card accounts using `get_accounts_by_type()` helper
    - Joins with liabilities table via account_id
    - Returns zero/false values if no credit cards found
  - Utilization calculation:
    - Calculates utilization per card: balance_current / balance_limit
    - Computes average utilization across all cards
    - Tracks max utilization (highest single card)
    - Sets utilization flags: ≥30%, ≥50%, ≥80% thresholds
  - Minimum payment detection:
    - Checks if last_payment <= minimum_payment (with $5 tolerance)
    - Sets `minimum_payment_only_flag` if any card matches pattern
  - Interest & overdue detection:
    - Queries transactions for interest charges using `category_detailed` filter (ilike '%interest%')
    - Checks `is_overdue` field on liabilities
    - Sets `interest_charges_present` and `any_overdue` flags
  - Returns dict with all 8 credit signals:
    - avg_utilization, max_utilization (float, 0-1)
    - utilization_30_flag, utilization_50_flag, utilization_80_flag (bool)
    - minimum_payment_only_flag, interest_charges_present, any_overdue (bool)
  - Error handling: Division by zero protection (when balance_limit = 0), debug logging
  - Test script updated (`scripts/test_feature_detection.py`) with comprehensive credit detection tests
  - Tests cover: high/low utilization, minimum payments, overdue accounts
  - Database path fix: Updated test script to use absolute path to `backend/spendsense.db`
- ✅ PR #9 Complete: Feature Detection Service - Income Signals (all 33 tasks finished)
  - Added `compute_income_signals()` function to feature_detection.py
  - Payroll identification:
    - Filters transactions for payroll deposits (ACH, positive amounts, income categories, or payroll merchant names)
    - Sorts transactions chronologically
    - Requires ≥2 payroll transactions to detect payroll
  - Income pattern analysis:
    - Calculates gaps between consecutive paydays
    - Computes median pay gap days using `statistics.median()`
    - Returns default values if <2 payroll transactions found
  - Income variability calculation:
    - Calculates mean and standard deviation of payroll amounts
    - Computes coefficient of variation (std_dev / mean)
    - Handles edge cases (mean = 0 or only 1 payment)
  - Cash flow buffer calculation:
    - Gets checking account balance
    - Estimates monthly expenses from checking account transactions
    - Calculates months of expenses covered by checking balance
    - Handles division by zero
  - Average monthly income:
    - Sums all payroll amounts in window
    - Divides by number of months, rounds to 2 decimal places
  - Investment account detection:
    - Added `detect_investment_accounts()` function
    - Queries for investment account types: brokerage, 401k, ira, roth_ira, investment, pension
    - Returns True/False if any exist
  - Test script updated with comprehensive income detection tests
- ✅ PR #10 Complete: Feature Computation Endpoint & Batch Script (all 28 tasks finished)
  - Created `compute_all_features()` function in feature_detection.py:
    - Calls all 4 signal detection functions (subscription, savings, credit, income)
    - Calls `detect_investment_accounts()`
    - Combines all results into single dict
    - Creates or updates UserFeature record in database
    - Returns computed features
  - Features router (`backend/app/routers/features.py`):
    - POST `/compute/{user_id}` endpoint with window_days query parameter (default: 30)
    - Error handling for user not found
  - Profile router (`backend/app/routers/profile.py`):
    - GET `/{user_id}` endpoint returns features (30d and/or 180d) and personas
    - Optional window filter
    - Error handling for user not found
  - Routers registered in main.py
  - Batch computation script (`scripts/compute_all_features.py`):
    - Processes all users, computes features for both 30-day and 180-day windows
    - Progress reporting every 10 users
    - Summary statistics (total users, avg time, duration)
  - Successfully created 142 feature records (71 users × 2 windows)
  - Average computation time: 0.013 seconds per user
- ✅ PR #11 Complete: Frontend - Project Setup & Basic Routing (all 39 tasks finished)
  - Vite configuration updated: Port set to 5173, path alias `@src` configured
  - API client setup (`frontend/src/lib/api.js`):
    - Axios instance with baseURL from environment variable
    - Request/response interceptors for logging and error handling
    - Default headers configured
  - API service functions (`frontend/src/lib/apiService.js`):
    - All 12 API functions created: getUsers, getUser, getUserProfile, getRecommendations, getOperatorDashboard, getOperatorUserSignals, getApprovalQueue, approveRecommendation, bulkApprove, updateConsent, getConsent
  - Routing setup (`frontend/src/App.jsx`):
    - React Router configured with BrowserRouter
    - Routes: / → /operator/dashboard, /operator/dashboard, /operator/users, /operator/users/:userId, /operator/approval-queue, /user/:userId/dashboard
  - Layout component (`frontend/src/components/Layout.jsx`):
    - Navigation header with active state styling
    - Links: Operator Dashboard, User List, Approval Queue
  - Page placeholders created:
    - OperatorDashboard, OperatorUserList, OperatorUserDetail, OperatorApprovalQueue, UserDashboard
  - Configuration files updated:
    - `vite.config.js`: Port 5173, `@src` alias with ES module path resolution
    - `tailwind.config.js`: ES module import for tailwindcss-animate plugin
    - `jsconfig.json`: Path alias `@src/*` for IDE resolution
- ✅ Python Environment Upgrade: Venv recreated with Python 3.11.9 (was 3.9.6)
  - All dependencies reinstalled with Python 3.11.9
  - VS Code settings updated with `python.analysis.diagnosticMode: "workspace"` for better import resolution
- ✅ PR #12 Complete: Frontend - Operator Dashboard (Metrics & Charts) (all 39 implementation tasks finished)
  - Dashboard data fetching (`frontend/src/pages/OperatorDashboard.jsx`):
    - useState/useEffect hooks for API data fetching
    - Loading, error, and data state management
    - Calls `getOperatorDashboard()` API function
    - Error handling with retry functionality
  - UI components created:
    - `MetricsCard.jsx`: Reusable metric card component using Shadcn Card
    - `skeleton.jsx`: Loading skeleton component for UI placeholders
    - `alert.jsx`: Error alert component with title and description
  - Dashboard layout:
    - Responsive grid layout (1 column mobile, 2 tablet, 4 desktop)
    - 4 metrics cards: Total Users, Users with Consent, Pending Approvals, Avg Latency
  - Charts implemented:
    - Persona Distribution chart: Bar chart showing persona counts using Recharts
    - Recommendation Status chart: Color-coded bar chart (pending=blue, approved=green, overridden=amber, rejected=red)
    - Data transformation from API objects to chart-friendly arrays
    - Responsive containers for all charts
  - Loading states:
    - Skeleton placeholders for metrics cards and charts
    - Loading state shown during data fetch
  - Error states:
    - Alert component displays error messages
    - Retry button allows re-fetching data
  - Fast Refresh fixes:
    - Removed "use client" directive (not needed in Vite/React)
    - Removed variant exports from badge.jsx and button.jsx (Fast Refresh requires component-only exports)
    - All imports updated to use `@src` alias consistently
- ✅ PR #13 Complete: Frontend - Operator User List Page & Backend Endpoints (all 61 tasks finished)
  - Frontend components created:
    - UserTable: Table component with columns (Name, Email, Persona 30d, Consent Status, Actions), colored badges for personas and consent, clickable rows
    - UserFilters: Filter dropdowns for user type and consent status using styled native selects
    - Pagination: Page navigation with previous/next buttons, page numbers (5 at a time), disabled states
    - UserTableSkeleton: Loading skeleton matching table structure
  - Frontend enum system:
    - Created `frontend/src/constants/enums.js` with UserType, ConsentStatus, ConsentAction enums
    - Helper functions for display formatting
    - Used throughout frontend for consistency (documented in systemPatterns.md)
  - OperatorUserList page:
    - State management: users, filteredUsers, loading, error, searchTerm, filters, pagination
    - Data fetching: useEffect with useCallback for fetchUsers, handles filters and pagination
    - Search: Debounced search (300ms) with local filtering by name or email
    - Loading states: Skeleton component during fetch
    - Error states: Alert component with retry button
    - Empty states: Different messages for search vs filter scenarios
    - Responsive layout: Flex layouts, mobile-friendly
  - Backend endpoints:
    - GET /users: Pagination (limit/offset), filters (user_type, consent_status), includes 30d personas for each user, returns users array with total count
    - GET /operator/dashboard: Total users, users with consent, persona distribution (30d), recommendation status breakdown, average latency metrics
  - Router registration: Both routers registered in main.py
  - All functionality tested and working
- ✅ PR #14 Complete: Frontend - Operator User Detail Page (all 52 implementation tasks finished)
  - Backend endpoints added:
    - GET /users/{user_id}: Returns user with personas for both 30d and 180d windows
    - GET /operator/users/{user_id}/signals: Returns detailed signals for operator view with:
      - 30d_signals and 180d_signals objects containing subscriptions, savings, credit, income
      - Recurring merchant names (array), credit card details (per-card), income frequency
      - Uses UserFeature data for most fields, queries additional details as needed
  - Frontend components created:
    - UserInfoCard: Displays user name, email, user type, consent status with badges, consent dates
    - PersonaDisplay: Shows persona type with large badge, confidence score as percentage, assigned date, color-coded by persona type
    - SignalDisplay: Comprehensive signal visualization component with 4 views:
      - Subscriptions: Recurring merchants count, monthly spend, spend share with progress bar, merchant list
      - Savings: Net inflow, growth rate, emergency fund coverage with color-coded progress bar (red/yellow/green)
      - Credit: Avg/max utilization with progress bars, per-card details (last_four, utilization, balance, limit), warning badges for flags
      - Income: Payroll detection badge, avg monthly income, pay gap, variability, cash flow buffer with warnings
    - Progress component: Shadcn-style progress bar component created
  - OperatorUserDetail page:
    - Two-column responsive layout (left: user info + personas, right: signals with tabs)
    - Tab navigation for signal types (subscriptions, savings, credit, income)
    - Displays signals for both 30d and 180d windows
    - Recommendations section: Fetches and displays recommendations with status badges, "Generate Recommendations" button placeholder
    - Back navigation button linking to user list
    - Loading states: Skeleton placeholders for all sections
    - Error states: Alert component with retry functionality
    - Data fetching: Parallel API calls for user, profile, signals, and recommendations
- ✅ **PR #15 Complete: Persona Assignment Service (all 29 tasks finished)**
  - Created `backend/app/services/persona_assignment.py` service file
  - Persona check functions implemented:
    - `check_high_utilization()`: Returns True if max_utilization >= 0.50 OR interest_charges_present OR minimum_payment_only_flag OR any_overdue
    - `check_variable_income()`: Returns True if median_pay_gap_days > 45 AND cash_flow_buffer_months < 1
    - `check_subscription_heavy()`: Returns True if recurring_merchants >= 3 AND (monthly_recurring_spend >= 50 OR subscription_spend_share >= 0.10)
    - `check_savings_builder()`: Returns True if (savings_growth_rate >= 0.02 OR net_savings_inflow >= 200) AND avg_utilization < 0.30
    - `check_wealth_builder()`: Returns True if avg_monthly_income > 10000 AND savings_balance > 25000 AND max_utilization <= 0.20 AND no overdrafts/late fees AND investment_account_detected
  - Helper functions:
    - `get_total_savings_balance()`: Queries savings accounts and sums balance_current
    - `has_overdraft_or_late_fees()`: Checks transactions for fee-related categories in window
  - Persona assignment logic (`assign_persona()`):
    - Queries UserFeature for user and window
    - Checks personas in priority order: wealth_builder (1.0), high_utilization (0.95 if util>=80%, else 0.8), savings_builder (0.7), variable_income (0.6), subscription_heavy (0.5)
    - Returns highest priority persona with confidence score and reasoning dictionary
    - Reasoning dict includes: matched_criteria, feature_values, timestamp, priority, all_matched_personas
  - Persona persistence (`create_or_update_persona()`):
    - Checks if Persona record exists for user + window
    - Updates existing or creates new record
    - Serializes reasoning dict to JSON string
    - Commits to database
  - Main function (`assign_and_save_persona()`):
    - Calls assign_persona() to get type, confidence, reasoning
    - Calls create_or_update_persona() to save
    - Returns Persona object
  - Test script created (`scripts/test_persona_assignment.py`):
    - Tests individual persona check functions
    - Tests persona assignment logic
    - Tests saving personas to database
    - Verifies persona records in database
    - Shows persona distribution statistics
- ✅ **PR #16 Complete: Persona Assignment Endpoint & Batch Script (all 29 tasks finished)**
  - Personas router (`backend/app/routers/personas.py`):
    - POST `/{user_id}/assign` endpoint: Assigns persona for user with optional window_days query parameter (default: 30)
    - GET `/{user_id}` endpoint: Retrieves personas for user with optional window filter
    - Error handling: 404 (user not found), 400 (features not computed), 500 (server error)
    - Returns PersonaResponse objects
  - Router registration: Personas router registered in main.py
  - Batch assignment script (`scripts/assign_all_personas.py`):
    - Processes all users, assigns personas for both 30-day and 180-day windows
    - Progress reporting every 10 users
    - Summary statistics: Total users processed, persona distribution for 30d and 180d windows, users with general_wellness
    - Validation warnings for missing persona types
  - Database schema update: Added 'general_wellness' to Persona model CHECK constraint and PersonaResponse schema
  - Successfully assigned personas to 71 users:
    - 30d window: 44 high_utilization, 10 subscription_heavy, 1 savings_builder, 16 general_wellness
    - 180d window: 44 high_utilization, 19 subscription_heavy, 8 general_wellness
  - Note: Some persona types (wealth_builder, variable_income) not represented in current synthetic data - will enhance data generation later for better variance
- ✅ **PR #17 Complete: OpenAI Integration Setup & Prompt Templates (all 50 tasks finished)**
  - OpenAI dependencies:
    - Added `openai==1.3.5` to `backend/requirements.txt`
    - Installed OpenAI SDK in virtual environment
    - API key configured in `.env.local` (already present)
    - `.gitignore` already covers `.env` files
  - Prompts infrastructure:
    - Created `backend/app/prompts/` directory with `__init__.py`
    - Created 5 self-contained persona-specific prompt files (following "just right" calibration guide)
    - Each prompt is ~42-52 lines (lean and focused)
    - Prompts follow structure: Role & Context, Core Principles, Response Framework, Guidelines, Output Format
  - Persona-specific prompts created:
    - `high_utilization.txt`: Credit card debt management strategies
    - `variable_income.txt`: Irregular income budgeting and cash flow strategies
    - `subscription_heavy.txt`: Subscription optimization and audit strategies
    - `savings_builder.txt`: Savings acceleration and goal-setting strategies
    - `wealth_builder.txt`: Investment/retirement education (with restrictions on specific investment advice)
  - Each prompt includes:
    - Core principles (regulatory compliance, data citation, empowering tone)
    - 5-step response framework for generating recommendations
    - Persona-specific guidelines with topic list ("When relevant, address topics like...")
    - JSON output format specification with mandatory disclosure
  - Prompt loader utility (`backend/app/utils/prompt_loader.py`):
    - `load_prompt(persona_type: str) -> str` function
    - File path construction and error handling
    - In-memory caching for performance
    - Helper functions for cache management
  - Prompt design decisions:
    - Self-contained prompts (no base template) for clarity and maintainability
    - Reduced prescription, increased principles (following "just right" calibration guide)
    - Simplified output format (no lengthy examples)
    - Topic lists included in guidelines for persona-specific depth
- ✅ **PR #18 Complete: Recommendation Engine Service - Context Building (all 34 tasks finished)**
  - Recommendation engine service (`backend/app/services/recommendation_engine.py`):
    - OpenAI client setup function (`get_openai_client()`) with API key from environment
    - User context builder (`build_user_context()`) that queries:
      - User record (user_id, basic info)
      - UserFeature record for window (all behavioral signals)
      - Persona record for window (persona_type)
      - Account records (top 5 by balance, with masked names like "Checking ****1234")
      - Recent transactions (last 10, last 30 days, with date, merchant, amount, type)
      - High utilization credit cards (when utilization ≥ 50%, includes balance, limit, utilization %, interest estimates)
      - Recurring merchants list (merchants with 3+ transactions in window)
      - Savings account growth info (when applicable, includes count, total balance, growth rate, emergency fund months)
    - Context structure:
      - Base info: user_id, window_days, persona_type
      - Subscription signals: recurring_merchants, monthly_recurring_spend, subscription_spend_share
      - Savings signals: net_savings_inflow, savings_growth_rate, emergency_fund_months
      - Credit signals: avg_utilization, max_utilization, utilization flags, payment patterns, interest/overdue status
      - Income signals: payroll_detected, median_pay_gap_days, income_variability, cash_flow_buffer_months, avg_monthly_income
      - Accounts: List of top 5 accounts with masked names and balances
      - Recent transactions: Last 10 transactions with formatted dates and amounts
      - Optional: high_utilization_cards, recurring_merchants, savings_accounts (when applicable)
    - Context validation (`validate_context()`):
      - Checks all required fields present
      - Validates data types
      - Logs errors for debugging
    - All float values rounded to 2 decimal places for readability
    - Token efficiency: Limits to top 5 accounts, last 10 transactions, top 10 recurring merchants
  - Test script (`scripts/test_context_builder.py`):
    - Tests context building for multiple users
    - Validates context structure and required fields
    - Checks data quality and realism
    - Estimates token count (target <2000 tokens)
    - Provides detailed output for review
  - Test results: All 5 users tested successfully, context validation passed, token counts well under target (583-764 tokens)
- ✅ **PR #19 Complete: Recommendation Engine Service - OpenAI Integration (all 26 tasks finished)**
  - OpenAI API integration (`generate_recommendations_via_openai()` function):
    - Loads persona-specific prompts using prompt_loader
    - Converts user context to JSON string
    - Calls OpenAI chat completions API (gpt-4o-mini, temperature 0.75, JSON response format)
    - Implements exponential backoff retry logic for rate limits (3 retries, 1s/2s/4s delays)
    - Comprehensive error handling (rate limits, invalid API key, model not found, JSON parsing)
    - Extracts and parses JSON response with validation
    - Validates required fields (title, content, rationale) for each recommendation
    - Adds generation_time_ms and persona_type to each recommendation
    - Token usage tracking (extracted from response, logged, calculated cost)
    - Token info included in metadata for review (NOT saved to DB - stripped before DB save)
  - Prompt improvements:
    - Added LANGUAGE STYLE section to all 5 persona prompts
    - Explicit requirements for empowering phrases: "You can...", "Let's explore...", "Many people find...", "Consider..."
    - Requirements to frame as opportunities and normalize challenges
    - Avoid directive language ("You should...", "You must...")
    - Temperature increased from 0.7 to 0.75 for more natural variation
  - Test script (`scripts/test_openai_generation.py`):
    - Tests all 5 persona types
    - Validates JSON response structure, recommendation count (3-5), required fields
    - Verifies rationales cite specific data
    - Checks content quality and tone (shaming language detection, empowering language verification)
    - Measures latency (target <5s, actual 9-22s acceptable for MVP)
    - Saves complete output to `openai_test_output.json` with token usage, costs, and recommendations
  - Test results: All 3 tested persona types passed quality checks, all recommendations use empowering language
  - OpenAI SDK upgraded from 1.3.5 to 2.7.1 for compatibility
- ✅ **PR #20 Complete: Guardrails Service - Tone & Consent Validation (all 38 tasks finished)**
  - Guardrails service (`backend/app/services/guardrails.py`):
    - `validate_tone()` function: Returns structured dict with `is_valid` and `validation_warnings` array
      - Critical warnings: Forbidden phrases (severity="critical", type="forbidden_phrase") → RED in operator UI
      - Notable warnings: Lacks empowering language (severity="notable", type="lacks_empowering_language") → YELLOW in operator UI
      - Empty array when valid, populated array with warnings when invalid
    - `check_consent()` function: Checks user consent status with logging
    - Eligibility functions: `check_income_eligibility()`, `check_credit_eligibility()`, `check_account_exists()`
    - `filter_partner_offers()` function: Filters offers based on eligibility requirements
    - `append_disclosure()` function: Appends mandatory disclosure to content
    - `MANDATORY_DISCLOSURE` constant defined
  - Test script (`scripts/test_guardrails.py`):
    - Tests tone validation with valid content, forbidden phrases, lacks empowering language, both issues
    - Tests consent checking with consented/non-consented/non-existent users
    - Tests eligibility checks (income, credit, account existence)
    - Tests partner offer filtering
    - Tests mandatory disclosure appending
  - Test results: All tests passing, all 38 tasks completed
  - Key design: All recommendations persisted regardless of warnings - operator reviews and decides
- ✅ **PR #21 Complete: Recommendation Generation Endpoint (all 44 tasks finished)**
  - Recommendations router (`backend/app/routers/recommendations.py`):
    - POST `/recommendations/generate/{user_id}` endpoint with full workflow
    - Query parameters: `window_days` (default: 30), `force_regenerate` (default: False)
    - User validation (404 if not found), consent check (403 if not consented)
    - Existing recommendations check (returns cached if exists and not force_regenerate)
    - Persona validation (400 if no persona assigned)
    - Context building and validation
    - OpenAI integration for recommendation generation
    - Tone validation for each recommendation with warnings stored in metadata
    - Database persistence with status='pending_approval' for all recommendations
    - Mandatory disclosure appended to content
    - Validation warnings stored in metadata_json (empty array for valid, populated for invalid)
    - Token usage and cost data stripped from metadata before saving (logging only)
    - Status codes: 200 for cached results, 201 for newly created
    - Comprehensive error handling with rollback on failures
  - Router registration: Recommendations router registered in main.py
  - Metadata design: Saves metadata (including validation_warnings) but excludes token_usage and estimated_cost_usd (used for logging/review only)
  - All recommendations persisted regardless of warnings for operator review
  - Tested and verified via Swagger UI
- ✅ **PR #22 Complete: Get Recommendations Endpoint (all 23 tasks finished)**
  - Recommendations router (`backend/app/routers/recommendations.py`):
    - GET `/recommendations/{user_id}` endpoint implemented
    - Query parameters: `status` (optional, filters by status), `window_days` (optional, filters by window_days)
    - User validation (404 if not found)
    - Query logic: Filters by user_id, optional status, optional window_days
    - Ordering: By generated_at descending (newest first)
    - Limit: 50 recommendations (pagination ready for future)
    - Response format: Returns recommendations list with all required fields and total count
    - Access control: Removed premature access control logic (will be implemented when authentication is added)
    - Error handling: 404 for user not found, 500 for database errors, comprehensive logging
    - Test script created (`scripts/test_get_recommendations.py`) for testing various filter combinations
  - Note: Access control removed - endpoint returns all recommendations when no status filter provided (authentication needed to determine requester identity)
- ✅ **PR #23 Complete: Approve Recommendation Endpoint (all 26 tasks finished)**
  - Recommendations router (`backend/app/routers/recommendations.py`):
    - POST `/recommendations/{recommendation_id}/approve` endpoint implemented
    - Accepts recommendation_id as path parameter
    - Accepts RecommendationApprove schema in body (operator_id, optional notes)
    - Validation: 404 if recommendation not found, 400 if already approved, 400 if status is 'rejected'
    - Updates recommendation: Sets status='approved', approved_by=operator_id, approved_at=current timestamp
    - Creates OperatorAction record for audit trail (action_type='approve', includes operator_id, recommendation_id, user_id, reason)
    - Returns updated recommendation with all fields
    - Error handling: 404 for not found, 400 for invalid state transitions, 500 for database errors
    - Comprehensive logging for all approve actions
  - Test script created (`scripts/test_approve_recommendation.py`) for testing approval workflow
  - All 26 tasks completed
- ✅ **PR #24 Complete: Override & Reject Endpoints (all 39 tasks finished)**
  - Recommendations router (`backend/app/routers/recommendations.py`):
    - POST `/recommendations/{recommendation_id}/override` endpoint implemented
    - POST `/recommendations/{recommendation_id}/reject` endpoint implemented
  - Schema updates:
    - Updated `RecommendationOverride` schema to make `new_title` and `new_content` optional
  - Override endpoint features:
    - Accepts recommendation_id as path parameter
    - Accepts RecommendationOverride schema (operator_id, optional new_title, optional new_content, required reason)
    - Validation: 404 if not found, 400 if neither new_title nor new_content provided
    - Stores original content in JSON format (original_title, original_content, overridden_at timestamp)
    - Updates recommendation: Sets status='overridden', updates title/content if provided, appends disclosure, validates tone
    - Tone validation: Rejects new content with critical warnings (forbidden phrases) → 400 error
    - Creates OperatorAction record with action_type='override'
    - Returns updated recommendation with original_content and override_reason
  - Reject endpoint features:
    - Accepts recommendation_id as path parameter
    - Accepts RecommendationReject schema (operator_id, required reason)
    - Validation: 404 if not found, 400 if already approved (can't reject approved recs)
    - Updates recommendation: Sets status='rejected', stores rejection reason in metadata_json
    - Metadata includes: rejection_reason, rejected_by, rejected_at
    - Creates OperatorAction record with action_type='reject'
    - Returns updated recommendation with rejection metadata
  - Error handling: 404 for not found, 400 for validation errors, 500 for database errors
  - Comprehensive logging for all override and reject actions
  - Test script created (`scripts/test_override_reject.py`) with 8 test cases
  - All 39 tasks completed

## Next Steps
1. **PR #25: Bulk Approve Endpoint** - Create API endpoint for bulk approving multiple recommendations at once

## Active Decisions and Considerations

### Immediate Priorities
- **Approval workflow endpoints** - PR #23 and PR #24 complete, PR #25 next - Create bulk approve endpoint for efficient operator workflow
- **Future Enhancement**: Enhance synthetic data generation to include more variance for all persona types

### Technical Decisions Made
- **Node version** - Node.js 20 LTS (documented in techContext.md and .cursor/rules/)
- **Python version** - Python 3.11.9 (upgraded from 3.9.6, venv recreated)
- **Package management** - Consolidated root .gitignore (Python + Node patterns)
- **Shadcn/ui** - Using `shadcn` (not deprecated `shadcn-ui`)
- **Synthetic data format** - JSON files that can seed both SQLite and production databases
- **Random seed** - Set to 42 for reproducibility
- **Data generation patterns** - Persona patterns distributed across users for realistic behavioral signals
- **Database** - SQLite for MVP (file: `backend/spendsense.db`)
- **SQLAlchemy** - Using declarative_base() pattern, relationships configured
- **Pydantic** - v2.5.0 with Literal types for enum validation, date parsing validators
- **CORS** - Configured for localhost:5173 (Vite) and localhost:3000 (React)
- **Frontend Routing** - React Router v7 configured with BrowserRouter, all routes set up
- **Path Aliases** - `@src` alias configured in vite.config.js and jsconfig.json for cleaner imports, all components updated to use `@src` consistently
- **Fast Refresh** - Component files export only React components (not constants/variants) for Fast Refresh compatibility
- **Batching** - Transactions processed in batches of 1000 for performance
- **Idempotency** - Duplicate key errors handled gracefully with 409 status
- **Pattern Detection** - Recurring pattern detection with ±5 day tolerance for weekly/monthly/quarterly intervals
- **Feature Detection** - Modular service design, helper functions reusable across signal types
- **Savings Detection** - Handles multiple savings accounts, calculates per-account growth rates and averages them
- **Credit Detection** - Queries credit card accounts and liabilities, calculates utilization metrics, detects payment patterns and overdue status
- **Income Detection** - Detects payroll deposits, calculates pay frequency, income variability, cash flow buffer, and average monthly income
- **Feature Computation** - Combines all signals, saves to database, provides API endpoints for computation and retrieval
- **Frontend Dashboard** - Operator dashboard complete with metrics cards, charts (persona distribution, recommendation status), loading/error states, responsive layout
- **Frontend User List** - Operator user list complete with table, filters, pagination, search, loading/error states, responsive layout
- **Frontend User Detail** - Operator user detail page complete with two-column layout, tabs, signal displays, recommendations section, back navigation, loading/error states
- **Frontend Components** - UserInfoCard, PersonaDisplay, SignalDisplay (all 4 signal types), Progress component
- **Frontend Enums** - Centralized enum system for UserType, ConsentStatus, ConsentAction with helper functions
- **Backend Users Endpoint** - GET /users with pagination, filters, and persona data; GET /users/{user_id} for single user
- **Backend Operator Endpoints** - GET /operator/dashboard with metrics and statistics; GET /operator/users/{user_id}/signals for detailed signals
- **OpenAI Integration** - OpenAI SDK installed (v2.7.1, upgraded from 1.3.5), API key configured, prompt templates created
- **Prompt System** - Self-contained persona-specific prompts following "just right" calibration guide, prompt loader utility with caching
- **Guardrails Service** - Complete guardrails service implemented (PR #20):
  - Tone validation with structured warnings (critical/notable) stored in metadata_json
  - Consent checking, eligibility validation (income, credit, accounts)
  - Partner offer filtering, mandatory disclosure appending
  - ALL recommendations persisted regardless of warnings for operator review
  - Operator UI will display RED (critical) and YELLOW (notable) warnings
  - Operator can approve/decline regardless of warnings

### Integration Points
- Frontend ↔ Backend: CORS configured, API client setup complete (`frontend/src/lib/api.js`), API service functions ready (`frontend/src/lib/apiService.js`), routing structure in place
- Backend ↔ Database: SQLAlchemy setup complete, all models implemented, data loaded (PR #3, #5 complete)
- Backend ↔ Feature Detection: Service module complete with all 4 signal types (PR #6, #7, #8, #9 complete)
- Backend ↔ Feature API: Features and profile endpoints created (PR #10 complete)
- Backend ↔ OpenAI: API key management via environment variables
- Backend ↔ AWS: S3 bucket setup pending
- Data Generation ↔ Database: ✅ Complete - All synthetic data ingested successfully

## Current Blockers
None - Ready to proceed with PR #21 (Recommendation Generation Endpoint)

## Active Questions
1. ✅ Python venv upgraded to 3.11.9 - Complete
2. ✅ All feature detection signals complete - Complete (PR #6-9)
3. ✅ Feature computation endpoint complete - Complete (PR #10)
4. Are AWS credentials configured for S3 exports?
5. Should we implement persona assignment before or after frontend setup?

## Workflow Notes
- PR #1 complete (all 41 tasks checked off)
- PR #2 complete (all 38 tasks checked off)
- PR #3 complete (all 58 tasks checked off)
- PR #4 complete (all 31 tasks checked off)
- PR #5 complete (all 30 tasks checked off)
- PR #6 complete (all 22 tasks checked off)
- PR #7 complete (all 20 tasks checked off)
- PR #8 complete (all 21 tasks checked off)
- PR #9 complete (all 33 tasks checked off)
- PR #10 complete (all 28 tasks checked off)
- PR #11 complete (all 39 tasks checked off)
- PR #12 complete (all 39 implementation tasks checked off)
- PR #13 complete (all 61 tasks checked off, including backend endpoints)
- PR #14 complete (all 52 implementation tasks checked off, including backend endpoints)
- PR #15 complete (all 29 tasks checked off - Persona Assignment Service)
- PR #16 complete (all 29 tasks checked off - Persona Assignment Endpoint & Batch Script)
- PR #17 complete (all 50 tasks checked off - OpenAI Integration Setup & Prompt Templates)
- PR #18 complete (all 34 tasks checked off - Recommendation Engine Service - Context Building)
- PR #19 complete (all 26 tasks checked off - Recommendation Engine Service - OpenAI Integration)
- PR #20 complete (all 38 tasks checked off - Guardrails Service - Tone & Consent Validation)
- PR #21 complete (all 44 tasks checked off - Recommendation Generation Endpoint)
- PR #22 complete (all 23 tasks checked off - Get Recommendations Endpoint)
- PR #23 complete (all 26 tasks checked off - Approve Recommendation Endpoint)
- PR #24 complete (all 39 tasks checked off - Override & Reject Endpoints)
- Following tasks-6.md structure (PR #25 next)
- Synthetic data generation produces JSON files that can be reused as seeds
- Data includes realistic persona patterns for testing feature detection
- All AI recommendations require operator approval before user visibility
- Consent is mandatory - no recommendations without opt-in
- Database schema matches synthetic data structure exactly
- Pydantic schemas validated and ready for API endpoints
- Data ingestion endpoint functional and tested
- All synthetic data successfully loaded into database
- Feature detection service complete with all 4 signal types (subscription, savings, credit, income)
- Feature computation endpoint and batch script working
- 142 feature records computed and saved to database (71 users × 2 windows)

